import arcpy
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA
import pandas as pd
import os
# This tool has been developed using the ArcGIS pro python3


Folder=arcpy.GetParameterAsText(0)
input=arcpy.GetParameterAsText(1)
table=os.path.join(Folder,'social.xls')
features=["P_00_14_JR","P_65_EO_JR","P_N_W_AL","P_LAAGINKP","WW_UIT_TOT","P_HUURWON","WOZ","INK_INW","AUTO_HH","AANT_VROUW","P_EENP_HH","BEV_DICHTH"]


#Make an excel table and read it as a pandas dataframe
arcpy.TableToExcel_conversion(Input_Table=input, Output_Excel_File=table, Use_field_alias_as_column_header="NAME", Use_domain_and_subtype_description="CODE")

db=pd.read_excel(table)
new_db=db[features].copy()
# turn the nagative values to null
for i in range(new_db.shape[0]):
    for x in range(new_db.shape[1]):
        if new_db.iloc[i][x] < 0:
            new_db._set_value(i, new_db.columns[x],None)

new_db.index.name="id"
new_db.dropna(inplace=True)
org_id=list(new_db.index)

# Principal component analysis
x=new_db.loc[:,features].values
x=StandardScaler().fit_transform(x)
pca=PCA(n_components=4)
principalComponents = pca.fit_transform(x)
principalDf = pd.DataFrame(data = principalComponents, columns = ['PC1', 'PC2','PC3','PC4'])
principalDf.index.name="id"
principalDf["org_id"]=org_id

# #Save the dataframe and join the field to the original file
pca_excel=os.path.join(Folder,'pca.xlsx')
pca_table=os.path.join(Folder,'pca')
principalDf.to_excel(pca_excel)
arcpy.ExcelToTable_conversion(Input_Excel_File=pca_excel,Output_Table=pca_table)
join_table=os.path.join(Folder,'pca.dbf')
arcpy.JoinField_management(in_data=input, in_field="FID", join_table=join_table, join_field="org_id", fields="PC1;PC2;PC3;PC4")
arcpy.AddField_management(in_table=input, field_name="PC", field_type='DOUBLE', field_precision="", field_scale="", field_length="", field_alias="", field_is_nullable="NULLABLE", field_is_required="NON_REQUIRED", field_domain="")

with arcpy.da.UpdateCursor(input, ['PC1','PC2','PC']) as socials:
    for social in socials:
        social[3] = (social[0] + social [1])/2
        socials.updateRow(social)


#Normalization
pcs=[]
with arcpy.da.SearchCursor(input, ['PC']) as rows:
    for row in rows:
        pcs.append(row[0])
pc_min = min(pcs)
pc_max = max(pcs)
arcpy.AddField_management(in_table=input, field_name="PCn", field_type='DOUBLE', field_precision="", field_scale="", field_length="", field_alias="", field_is_nullable="NULLABLE", field_is_required="NON_REQUIRED", field_domain="")
with arcpy.da.UpdateCursor(input, ['PC','PCn']) as datas:
    for data in datas:
        if data[0] == 0:
            data[1] =0
        else:
            data[1] = (data[0] - pc_min) / (pc_max - pc_min)
            data[1]= 1 - data[1]
        datas.updateRow(data)

